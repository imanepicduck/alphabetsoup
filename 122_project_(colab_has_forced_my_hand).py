# -*- coding: utf-8 -*-
"""122 project (colab has forced my hand)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ujJ7HSdnUxORdYRpiBRURiGiz6jzaVkH
"""
#importing libraries and other stuff
import pandas as pd
import numpy as np
import cv2
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from PIL import Image
import PIL.ImageOps
import os, ssl, time

#importing the image
from google.colab import files
data = files.upload()
X = np.load('image.npz')['arr_0']

#importing the csv 
from google.colab import files
data = files.upload()
y = pd.read_csv("labels.csv")["labels"]
print(pd.Series(y).value_counts())
classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
nclasses = len(classes)

#setting a https thing to fetch some data
if (not os.environ.get('PYTHONHTTPSVERIFY', '') and
    getattr(ssl, '_create_unverified_context', None)):
    ssl._create_default_https_context = ssl._create_unverified_context
 
#making a chart/figure, i don't know what else to call it
samples_per_class = 5
figure = plt.figure(figsize=(nclasses*2, (1+samples_per_class*2)))

#making a for loop for the chart
idx_cls = 0
for cls in classes:
  idxs = np.flatnonzero (y == cls)
  idxs = np.random.choice (idxs, samples_per_class, replace = False)
  i = 0
  for idx in idxs:
    plt_idx = i*nclasses + idx_cls + 1
    p = plt.subplot(samples_per_class, nclasses, plt_idx)
    p = sns.heatmap(np.reshape(X[idx], (22, 30), cmap=plt.cm.gray, xticklabels = False, yticklabels = False, cbar = False))
    p = plt.axis('off')
    i+=1
  idx_cls+=1

#printing a certain length of the image and csv
print(len(X))
print(len(y))

#setting it to 0
print(X[0])
print(y[0])

#splitting the model for training and testing, also scaled it down
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9, train_size=7500, test_size=2500)
X_trained_scaled = X_train/255.0
X_tested_scaled = X_test/255.0

#using logistic regression to test said model
clf = LogisticRegression(solver='saga', multi_class='multinomial').fit(X_trained_scaled, y_train)

#predicting the accuracy
y_pred = clf.predict(X_tested_scaled)
accuracy=accuracy_score(y_test, y_pred)
print(accuracy)

#making the confusion matrix
cm = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])
p = plt.figure(figsize=(10,10));
p = sns.heatmap(cm, annot=True, fmt = 'd', cbar = False)

#opening my web cam 
cap = cv2.VideoCapture(0)

while(True):
  # Capture frame-by-frame
  try:
    ret, frame = cap.read()
 
    # Our operations on the frame come here
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
   
    #Drawing a box in the center of the video
    height, width = gray.shape
    upper_left = (int(width / 2 - 56), int(height / 2 - 56))
    bottom_right = (int(width / 2 + 56), int(height / 2 + 56))
    cv2.rectangle(gray, upper_left, bottom_right, (0, 255, 0), 2)
 
    #To only consider the area inside the box for detecting the digit
    #roi = Region Of Interest
    roi = gray[upper_left[1]:bottom_right[1], upper_left[0]:bottom_right[0]]
 
    #Converting cv2 image to pil format
    im_pil = Image.fromarray(roi)
 
    # convert to grayscale image - 'L' format means each pixel is
    # represented by a single value from 0 to 255
    image_bw = im_pil.convert('L')
    image_bw_resized = image_bw.resize((28,28), Image.ANTIALIAS)
 
    image_bw_resized_inverted = PIL.ImageOps.invert(image_bw_resized)
    pixel_filter = 20
    min_pixel = np.percentile(image_bw_resized_inverted, pixel_filter)
    image_bw_resized_inverted_scaled = np.clip(image_bw_resized_inverted-min_pixel, 0, 255)
    max_pixel = np.max(image_bw_resized_inverted)
    image_bw_resized_inverted_scaled = np.asarray(image_bw_resized_inverted_scaled)/max_pixel
    test_sample = np.array(image_bw_resized_inverted_scaled).reshape(1,784)
    test_pred = clf.predict(test_sample)
    print("Predicted class is: ", test_pred)
 
    # Display the resulting frame
    cv2.imshow('frame',gray)
    if cv2.waitKey(1) & 0xFF == ord('q'):
      break
  except Exception as e:
    pass
 
# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()
